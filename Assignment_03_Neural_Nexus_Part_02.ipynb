{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3JoQapuc5jo"
      },
      "source": [
        "## Compare the network with state-of-the-art networks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "N6DUhmgahfqe",
        "outputId": "0f3d624c-c9d6-4c17-8ca6-f54fff973397",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ],
      "metadata": {
        "id": "PdGdSqpdc8Oy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "train_dir = '/content/drive/My Drive/EN3150-Assignment-03-CNN/Images/train'\n",
        "validation_dir = '/content/drive/My Drive/EN3150-Assignment-03-CNN/Images/validation'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='sparse'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='sparse'\n",
        ")\n"
      ],
      "metadata": {
        "id": "1jnlhGmFhAwG",
        "outputId": "4cc73616-566e-48eb-ac29-36a8681ac6f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5468 images belonging to 5 classes.\n",
            "Found 1823 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained ResNet50 model without the top layers\n",
        "base_model_resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Add custom layers on top\n",
        "x = base_model_resnet.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(5, activation='softmax')(x)  # 5 classes\n",
        "\n",
        "# Create the model\n",
        "model_resnet = Model(inputs=base_model_resnet.input, outputs=x)\n",
        "\n",
        "# Freeze the base model layers\n",
        "for layer in base_model_resnet.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model_resnet.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history_resnet = model_resnet.fit(\n",
        "    train_generator,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "cOZM3DWJhzdF",
        "outputId": "6b3431e0-e1f4-4270-d891-5fb88751f92d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1504s\u001b[0m 8s/step - accuracy: 0.4274 - loss: 1.4268 - val_accuracy: 0.4833 - val_loss: 1.3402\n",
            "Epoch 2/20\n",
            "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1272s\u001b[0m 7s/step - accuracy: 0.4789 - loss: 1.3457 - val_accuracy: 0.4833 - val_loss: 1.3374\n",
            "Epoch 3/20\n",
            "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.4908 - loss: 1.3340"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to save the model\n",
        "save_path = '/content/drive/My Drive/models/model_resnet.h5'\n",
        "\n",
        "# Save the model\n",
        "model_resnet.save(save_path)\n",
        "\n",
        "# Confirm the model has been saved\n",
        "print(\"Model saved successfully!\")\n"
      ],
      "metadata": {
        "id": "_HmmlhsKYhlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract loss values from the history object\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Extract the number of epochs\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "# Plot the training and validation loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, train_loss, label='Training Loss')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rwf9KskEXQDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create the test data generator\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Parameters\n",
        "\n",
        "img_size = (224, 224)  # Replace with your model's expected input size\n",
        "batch_size = 32  # Adjust batch size if needed\n",
        "\n",
        "# Load the test data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='sparse',\n",
        "    shuffle=False  # No shuffling to preserve order\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "MjmB9Av8Uq86"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}